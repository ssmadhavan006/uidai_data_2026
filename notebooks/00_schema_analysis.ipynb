{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "ceae2e24",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading datasets...\n",
                        "Found 3 files for pattern '*enrolment*.csv'\n",
                        "Loaded api_data_aadhar_enrolment_0_500000.csv: 500000 rows\n",
                        "Loaded api_data_aadhar_enrolment_1000000_1006029.csv: 6029 rows\n",
                        "Loaded api_data_aadhar_enrolment_500000_1000000.csv: 500000 rows\n",
                        "Found 5 files for pattern '*demographic*.csv'\n",
                        "Loaded api_data_aadhar_demographic_0_500000.csv: 500000 rows\n",
                        "Loaded api_data_aadhar_demographic_1000000_1500000.csv: 500000 rows\n",
                        "Loaded api_data_aadhar_demographic_1500000_2000000.csv: 500000 rows\n",
                        "Loaded api_data_aadhar_demographic_2000000_2071700.csv: 71700 rows\n",
                        "Loaded api_data_aadhar_demographic_500000_1000000.csv: 500000 rows\n",
                        "Found 4 files for pattern '*biometric*.csv'\n",
                        "Loaded api_data_aadhar_biometric_0_500000.csv: 500000 rows\n",
                        "Loaded api_data_aadhar_biometric_1000000_1500000.csv: 500000 rows\n",
                        "Loaded api_data_aadhar_biometric_1500000_1861108.csv: 361108 rows\n",
                        "Loaded api_data_aadhar_biometric_500000_1000000.csv: 500000 rows\n",
                        "All datasets loaded.\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import glob\n",
                "import os\n",
                "\n",
                "# Function to load and concatenate matching files from split CSVs\n",
                "def load_dataset(pattern):\n",
                "    # Look for files in ../data/raw/ matching the pattern\n",
                "    search_path = os.path.join('../data/raw', pattern)\n",
                "    files = glob.glob(search_path)\n",
                "    print(f\"Found {len(files)} files for pattern '{pattern}'\")\n",
                "    \n",
                "    if not files:\n",
                "        print(f\"Warning: No files found for {pattern}\")\n",
                "        return pd.DataFrame()\n",
                "    \n",
                "    dfs = []\n",
                "    for f in files:\n",
                "        try:\n",
                "            df = pd.read_csv(f)\n",
                "            dfs.append(df)\n",
                "            print(f\"Loaded {os.path.basename(f)}: {len(df)} rows\")\n",
                "        except Exception as e:\n",
                "            print(f\"Error reading {f}: {e}\")\n",
                "            \n",
                "    if not dfs:\n",
                "        return pd.DataFrame()\n",
                "        \n",
                "    return pd.concat(dfs, ignore_index=True)\n",
                "\n",
                "print(\"Loading datasets...\")\n",
                "enrolment = load_dataset('*enrolment*.csv')\n",
                "demo_update = load_dataset('*demographic*.csv') \n",
                "bio_update = load_dataset('*biometric*.csv')\n",
                "print(\"All datasets loaded.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "d0878f05",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== Enrolment Dataset ===\n",
                        "Rows: 1006029\n",
                        "Date range: 01-04-2025 to 31-12-2025\n",
                        "States: 55\n",
                        "Districts: 985\n",
                        "Age columns: ['age_0_5', 'age_5_17', 'age_18_greater']\n",
                        "\n",
                        "=== Demographic Update Dataset ===\n",
                        "Rows: 2071700\n",
                        "Date range: 01-03-2025 to 31-10-2025\n",
                        "States: 65\n",
                        "Districts: 983\n",
                        "Age columns: ['demo_age_5_17', 'demo_age_17_']\n",
                        "\n",
                        "=== Biometric Update Dataset ===\n",
                        "Rows: 1861108\n",
                        "Date range: 01-03-2025 to 31-10-2025\n",
                        "States: 57\n",
                        "Districts: 974\n",
                        "Age columns: ['bio_age_5_17', 'bio_age_17_']\n"
                    ]
                }
            ],
            "source": [
                "# Basic stats for each\n",
                "def print_stats(name, df):\n",
                "    if df.empty:\n",
                "        print(f\"\\n=== {name} Dataset is EMPTY ===\")\n",
                "        return\n",
                "        \n",
                "    print(f\"\\n=== {name} Dataset ===\")\n",
                "    print(f\"Rows: {len(df)}\")\n",
                "    if 'date' in df.columns:\n",
                "        print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
                "    print(f\"States: {df['state'].nunique() if 'state' in df.columns else 'N/A'}\")\n",
                "    print(f\"Districts: {df['district'].nunique() if 'district' in df.columns else 'N/A'}\")\n",
                "    print(f\"Age columns: {[c for c in df.columns if 'age' in c]}\")\n",
                "\n",
                "print_stats(\"Enrolment\", enrolment)\n",
                "print_stats(\"Demographic Update\", demo_update)\n",
                "print_stats(\"Biometric Update\", bio_update)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "89e020dc",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== Can we merge? ===\n",
                        "Common columns: {'state', 'pincode', 'district', 'date'}\n"
                    ]
                }
            ],
            "source": [
                "# Check for merging\n",
                "if not enrolment.empty and not demo_update.empty and not bio_update.empty:\n",
                "    print(\"\\n=== Can we merge? ===\")\n",
                "    common_cols = set(enrolment.columns) & set(demo_update.columns) & set(bio_update.columns)\n",
                "    print(f\"Common columns: {common_cols}\")\n",
                "    # Should be: date, state, district, pincode"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "c94d6663",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Testing merge on first 100 rows...\n",
                        "Merged shape: (200, 9)\n"
                    ]
                }
            ],
            "source": [
                "# Sample merge test\n",
                "if not enrolment.empty:\n",
                "    # Create lighter subsets for testing merge to avoid memory issues\n",
                "    print(\"\\nTesting merge on first 100 rows...\")\n",
                "    merged_sample = pd.merge(\n",
                "        enrolment.head(100),\n",
                "        demo_update.head(100),\n",
                "        on=['date', 'state', 'district', 'pincode'],\n",
                "        how='outer'\n",
                "    )\n",
                "    print(f\"Merged shape: {merged_sample.shape}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
